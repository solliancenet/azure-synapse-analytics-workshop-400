{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Install Synapse ML in the Apache Spark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%configure -f\n",
        "{\n",
        "    \"name\": \"synapseml\",\n",
        "    \"conf\": {\n",
        "        \"spark.jars.packages\": \"com.microsoft.azure:synapseml_2.12:0.9.4\",\n",
        "        \"spark.jars.repositories\": \"https://mmlspark.azureedge.net/maven\",\n",
        "        \"spark.jars.excludes\": \"org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalactic:scalactic_2.12,org.scalatest:scalatest_2.12\",\n",
        "        \"spark.yarn.user.classpath.first\": \"true\"\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Part 1 - Entity detection with Cognitive Services\n",
        "\n",
        "Detect entities in text using the Cognitive Services entity detector transformer from Synapse ML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Retrieve the Cognitive Services credentials and create the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "key = mssparkutils.credentials.getSecret('#KEY_VAULT_NAME#', '#COGNITIVE_SERVICES_SECRET_NAME#')\n",
        "location = '#COGNITIVE_SERVICES_ACCOUNT_LOCATION#'\n",
        "\n",
        "df = spark.createDataFrame(data=[\n",
        "        [1, \"Muad'Dib learned rapidly because his first training was in how to learn. And the first lesson of all was the basic trust that he could learn. It's shocking to find how many people do not believe they can learn, and how many more believe learning to be difficult. Muad'Dib knew that every experience carries its lesson.\"],\n",
        "        [2, \"It's the ship that made the Kessel run in less than twelve parsecs. I've outrun Imperial starships. Not the local bulk cruisers, mind you. I'm talking about the big Corellian ships, now. She's fast enough for you, old man.\"]\n",
        "    ], \n",
        "    schema=[\"id\",\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Define the transformer to detect the entities mentioned in text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from synapse.ml.cognitive import *\n",
        "\n",
        "entity = (EntityDetector()\n",
        "      .setSubscriptionKey(key)\n",
        "      .setLocation(location)\n",
        "      .setLanguage(\"en\")\n",
        "      .setOutputCol(\"entities\")\n",
        "      .setErrorCol(\"error\"))\n",
        "\n",
        "df_entities = entity.transform(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Check out the entities identified from the first phrase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "print(df_entities.head(1)[0].entities[0].entities[0].id)\n",
        "print(df_entities.head(1)[0].entities[0].entities[0].url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Check out the entities identified from the second phrase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "print(df_entities.tail(1)[0].entities[0].entities[0].id)\n",
        "print(df_entities.tail(1)[0].entities[0].entities[0].url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Part 2 - Train a customer recommendation model\n",
        "\n",
        "Use the LightGBM Synapse ML algorithm to train a model for retail product recommendation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Configure\n",
        "\n",
        "Reference the required libraries and check Synapse ML version (shoudl be 0.9.4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.getLogger(\"py4j\").setLevel(logging.ERROR)\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from pyspark.version import __version__ as pyspark_version\n",
        "\n",
        "from synapse.ml.core import __spark_package_version__\n",
        "from synapse.ml.train import ComputeModelStatistics\n",
        "from synapse.ml.lightgbm import LightGBMClassifier\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "pd.set_option('display.max_columns', 50)\n",
        "\n",
        "print(f\"PySpark version: {pyspark_version}\")\n",
        "print(f\"SynapseML version: {__spark_package_version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the data preparation and model training parameters. \n",
        "\n",
        "Check the [Synapse ML LightGBM documentation](https://microsoft.github.io/SynapseML/docs/features/lightgbm/LightGBM%20-%20Overview/) for more details on setting the parameters of the ML model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Blob url\n",
        "# Original blob: \"https://recodatasets.z20.web.core.windows.net/random-dataset/PersonalizedData.csv\"\n",
        "url = \"wasbs://files@synapsemlpublic.blob.core.windows.net/PersonalizedData.csv\"\n",
        "\n",
        "# Data parameters\n",
        "LABEL_COL = \"Rating\"\n",
        "FEATURE_COL = \"features\"\n",
        "RATIO = 0.8\n",
        "SEED = 42\n",
        "\n",
        "# Model parameters\n",
        "OBJECTIVE = \"binary\"\n",
        "BOOSTING = \"gbdt\"\n",
        "NUM_LEAVES = 32\n",
        "NUM_ITERATIONS = 100\n",
        "LEARNING_RATE = 0.1\n",
        "FEATURE_FRACTION = 0.8\n",
        "EARLY_STOPPING_ROUND = 10\n",
        "MODEL_NAME = \"lgb-quickstart\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Prepare and analyze data\n",
        "\n",
        "\n",
        "Load the data from the source and observe the schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Added the file to linked ADLSv2\n",
        "raw_data = spark.read.csv(url, header=True, inferSchema=True)\n",
        "print(\"Schema: \")\n",
        "# raw_data.printSchema()\n",
        "\n",
        "df = raw_data.toPandas()\n",
        "print(\"Shape: \", df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "\n",
        "Take a look at some of the items in the dataset. Notice the two-class ratings (0 vs. 1) provided by customers to products.\n",
        "The goal of this exercise is to build a Machine Learning classification model capable of predicting the rating based on Cost, Size, Price, PrimaryBrandId, GenderId, MaritalStatus, LowerIncomeBound, and UpperIncomeBound. To achieve the goal, you will use Azure Machine Learning (AML) automated machine learning (Auto ML)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display(df.iloc[:10, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Check out the statistical properties of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Calculate and display the dataset fratures correlation matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# calculate the correlation matrix\n",
        "corr = df.corr()\n",
        "\n",
        "# plot the correlation heatmap\n",
        "fig, ax = plt.subplots(figsize=(10,10))         # Sample figsize in inches\n",
        "\n",
        "sns.heatmap(corr, \n",
        "            xticklabels=corr.columns, \n",
        "            yticklabels=corr.columns, \n",
        "            cmap='RdBu', \n",
        "            vmin=-1, \n",
        "            vmax=1, \n",
        "            ax=ax, \n",
        "            annot=True,\n",
        "            fmt='.2f', \n",
        "            annot_kws={'size': 10})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Display the paiwise feature correlations as scatterplots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#scatterplot\n",
        "sns.set()\n",
        "sns.pairplot(df, height=2.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Train the ML model\n",
        "\n",
        "Split the dataset into train and test subsets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "raw_train, raw_test = raw_data.randomSplit([RATIO, 1 - RATIO], seed=SEED)\n",
        "print(\"Train: (rows, columns) = {}\".format((raw_train.count(), len(raw_train.columns))))\n",
        "print(\"Test: (rows, columns) = {}\".format((raw_test.count(), len(raw_test.columns))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Perform feature engineering - transform the original data feature columns into feature vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "columns = raw_data.columns[3:]\n",
        "featurizer = VectorAssembler(inputCols=columns, outputCol=FEATURE_COL)\n",
        "train = featurizer.transform(raw_train)[LABEL_COL, FEATURE_COL]\n",
        "test = featurizer.transform(raw_test)[LABEL_COL, FEATURE_COL]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Check if data is unbalanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "display(train.groupBy(LABEL_COL).count())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Define the LBGM model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "lgbm = LightGBMClassifier(\n",
        "    labelCol=LABEL_COL,\n",
        "    featuresCol=FEATURE_COL,\n",
        "    objective=OBJECTIVE,\n",
        "    isUnbalance=False,\n",
        "    boostingType=BOOSTING,\n",
        "    boostFromAverage=True,\n",
        "    baggingSeed=SEED,\n",
        "    numLeaves=NUM_LEAVES,\n",
        "    numIterations=NUM_ITERATIONS,\n",
        "    learningRate=LEARNING_RATE,\n",
        "    featureFraction=FEATURE_FRACTION,\n",
        "    earlyStoppingRound=EARLY_STOPPING_ROUND\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Train the LGBM model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model = lgbm.fit(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the relative feature importance as it results from the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_importances = model.getFeatureImportances()\n",
        "fi = pd.Series(feature_importances,index = columns)\n",
        "fi = fi.sort_values(ascending = True)\n",
        "f_index = fi.index\n",
        "f_values = fi.values\n",
        " \n",
        "# print feature importances \n",
        "print ('f_index:',f_index)\n",
        "print ('f_values:',f_values)\n",
        "\n",
        "# plot\n",
        "x_index = list(range(len(fi)))\n",
        "x_index = [x/len(fi) for x in x_index]\n",
        "plt.rcParams['figure.figsize'] = (10,10)\n",
        "plt.barh(x_index,f_values,height = 0.028 ,align=\"center\",color = 'tan',tick_label=f_index)\n",
        "plt.xlabel('importances')\n",
        "plt.ylabel('features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform predictions with the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "predictions = model.transform(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display(predictions.limit(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Evaluate the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "evaluator = (\n",
        "    ComputeModelStatistics()\n",
        "    .setScoredLabelsCol(\"prediction\")\n",
        "    .setLabelCol(LABEL_COL)\n",
        "    .setEvaluationMetric(\"classification\")\n",
        ")\n",
        "\n",
        "metrics = evaluator.transform(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Observe the main performance metrics of a classification model:\n",
        "\n",
        "- Confision matrix\n",
        "- Accuracy\n",
        "- Precision\n",
        "- Recall\n",
        "- AUC (Area Under the Curve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "display(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Save the model\n",
        "\n",
        "Save the model to storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "print(MODEL_NAME)\n",
        "(model\n",
        " .write()\n",
        " .overwrite()\n",
        " .save(MODEL_NAME))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "##"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
