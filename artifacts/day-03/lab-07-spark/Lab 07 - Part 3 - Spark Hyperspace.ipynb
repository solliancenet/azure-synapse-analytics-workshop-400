{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Using Hyperspace for indexing in Synapse Spark\r\n",
        "\r\n",
        "Hyperspace introduces the ability for Apache Spark users to create indexes on their datasets, such as CSV, JSON, and Parquet, and use them for potential query and workload acceleration.\r\n",
        "\r\n",
        "Hyperspace helps accelerate your workloads or queries under two circumstances:\r\n",
        "\r\n",
        "- Queries contain filters on predicates with high selectivity. For example, you might want to select 100 matching rows from a million candidate rows.\r\n",
        "- Queries contain a join that requires heavy shuffles. For example, you might want to join a 100-GB dataset with a 10-GB dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "By default, Spark uses broadcast join to optimize join queries when the data size for one side of join is small (which is the case for the sample data we use in this tutorial). Therefore, we disable broadcast joins so that later when we run join queries, Spark uses sort-merge join. This is mainly to show how Hyperspace indexes would be used at scale for accelerating join queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Disable BroadcastHashJoin, so Spark will use standard SortMergeJoin. Currently, Hyperspace indexes utilize SortMergeJoin to speed up query.\r\n",
        "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\r\n",
        "\r\n",
        "# Verify that BroadcastHashJoin is set correctly \r\n",
        "print(spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Load customer data into a Spark dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "df_customer = spark.read.load('abfss://wwi-02@#DATA_LAKE_ACCOUNT_NAME#.dfs.core.windows.net/data-generators/generator-customer.csv', format='csv', header=True)\r\n",
        "display(df_customer.limit(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Load sales data into a Spark dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "df_sales = spark.read.load('abfss://wwi-02@#DATA_LAKE_ACCOUNT_NAME#.dfs.core.windows.net/sale-small/Year=2019/Quarter=Q4/Month=12/*/sale-small-20191201-snappy.parquet', format='parquet')\r\n",
        "display(df_sales.limit(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Initialize the Hyperspace engine in the Spark session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from hyperspace import *  \r\n",
        "from com.microsoft.hyperspace import *\r\n",
        "from com.microsoft.hyperspace.index import *\r\n",
        "\r\n",
        "# Create an instance of Hyperspace\r\n",
        "hyperspace = Hyperspace(spark)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Create index configurations for customer and sales data as follows:\r\n",
        "- The customer index is built on the `CustomerId` column and also includes (covers) column `BirthDate`\r\n",
        "- The sales index is built on the `CustomerId` column and also includes (covers) columns `ProductId` and `Quantity`\r\n",
        "\r\n",
        "Using the index configurations, create the actual indexes on the customer and sales dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "customer_index_config = IndexConfig(\"customerIndex1\", [\"CustomerId\"], [\"BirthDate\"])\r\n",
        "sales_index_config = IndexConfig(\"salesIndex1\", [\"CustomerId\"], [\"ProductId\", \"Quantity\"])\r\n",
        "\r\n",
        "hyperspace.createIndex(df_customer, customer_index_config)\r\n",
        "hyperspace.createIndex(df_sales, sales_index_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Enumerate all available indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "hyperspace.indexes().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Check the data lake location of the first index from the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "hyperspace.indexes().first().indexLocation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Hyperspace provides APIs to enable or disable index usage with Spark.\r\n",
        "\r\n",
        "- By using the **hyperspace.enable()** command, Hyperspace optimization rules become visible to the Spark optimizer and exploit existing Hyperspace indexes to optimize user queries.\r\n",
        "- By using the **hyperspace.disable()** command, Hyperspace rules no longer apply during query optimization. Disabling Hyperspace has no impact on created indexes because they remain intact.\r\n",
        "\r\n",
        "Enable hyperspace on the current Spark session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "hyperspace.enable(spark)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Currently, Hyperspace has rules to exploit indexes for two groups of queries:\r\n",
        "\r\n",
        "- Selection queries with lookup or range selection filtering predicates.\r\n",
        "- Join queries with an equality join predicate (that is, equijoins).\r\n",
        "\r\n",
        "Observe the impact of Hyperspace on range selection. Start with a filtering predicate followed by a selection that contains columns not covered by the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "sales_filter = df_sales.filter('CustomerId = 85100').select(['CustomerId', 'TransactionDate'])\r\n",
        "sales_filter.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Observe the impact of the Hyperspace index. Note how the physical plan scans the actual data files (this happens because `TransactionDate` is not covered by the index, thus it needs to be loaded from the original data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "spark.conf.set(\"spark.hyperspace.explain.displayMode\", \"html\")\r\n",
        "\r\n",
        "hyperspace.explain(sales_filter, True, displayHTML)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Perform the same filtering but with a selection that is covered by the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "sales_filter = df_sales.filter('CustomerId == 85100').select(['CustomerId', 'ProductId', 'Quantity'])\r\n",
        "sales_filter.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Observe how the plan relies now in the Hyperspace index for execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "hyperspace.explain(sales_filter, True, displayHTML)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Perform a join between the customer and sales dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "customers_sales_join = df_customer.join(df_sales, df_customer.CustomerId == df_sales.CustomerId).select(df_sales.CustomerId, df_sales.ProductId, df_customer.BirthDate, df_sales.Quantity)\r\n",
        "customers_sales_join.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Observe the impact of both indexes in the execution plan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "hyperspace.explain(customers_sales_join, True, displayHTML)"
      ]
    }
  ]
}