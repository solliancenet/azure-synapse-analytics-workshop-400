# Unanswered questions


### **Q**: _Can Synapse write to Amazon S3?_

**A**: 

---

### **Q**: _Is there a plan for ADF Azure IR to be placed within Vnet?_

**A**: 

---

### **Q**: _The customer requires integration into Azure VNets. Is this available / planned for the near future? Private link? The customer does not like SHIR on VMs at all - aims for pure PaaS._

**A**: 

---

### **Q**: _Any suggested wrapper for Data Quality Assessment capability? _

**A**: 

---

### **Q**: _What is the difference between data flow and data pipeline?_

**A**: 

---

### **Q**: _Do you have any guidelines or material on team development and the CI/CD story for Azure Synapse as a whole? Users directly exploring data in a prod data lake is very different from users building new data pipelines and needing to keep track of versioning and automating deployments through dev/test/prod._

**A**: 

---

### **Q**: _I assume it also doesn't support koalas because of the DataBricks runtime dependency?_

**A**: 

---

### **Q**: _Are the credentials passthrough from a spark notebook to a SQL pool? i.e., if the User has RLS in spark SQL, that filtering can be applied?_

**A**: 

---

### **Q**: _Are we planning to have a way to mount external storage in the spark cluster similar to what DataBricks has with dbutils? Reason here is that it makes life a lot easier to bring python scripts to run in Synapse._

**A**: 

---

### **Q**: _In Databricks, when configuring a cluster, all cluster infrastructure is provisioned to a "managed resource group" that you can see in your Azure portal. Are the nodes in the Spark pool cluster visible in the portal or completely abstracted?_

**A**: 

---

### **Q**: _Can you upload a DataBricks notebook into Synapse?_

**A**: 

---

### **Q**: _When using python, do we plan to have any better analysis (as compared to Databricks) of cluster performance? My number one customer issue with Databricks is using python libraries in a terrible way that means parallelization gets shot._

**A**: 

---

### **Q**: _Generally, the cost is the big concern when customer use spark cluster, is there any plan to have cost\budget control in spark pool to avoid overspending? I keep hearing this question from a couple of regulated customers._

**A**: 

---

### **Q**: _Will there be more support for the perf options like caching or index optimizations in the orchestration part (ADF & data flow), with stored procedures it should be doable, but seems not to be well integrated yet._

**A**: 

---

### **Q**: _What are the best practices for relatively small volumes of data (2-3 Tb of data for the entire DWH) with Synapse?_

**A**: 

---

### **Q**: _Can we get more guidance on the result caching?_

**A**: 

---

### **Q**: _What is the best approach to reduce downtime during DWH loading or even ensure full query capabilities during a load?_

**A**: 

---

### **Q**: _How does a stage load method compare to Snowflake loading?_

**A**: 

---

### **Q**: _Does distribution matter under DW1000C?_

**A**: 

---

### **Q**: _Can the User configure an upper bound on the resources allocated for SQL Serverless?_

**A**: 

---

### **Q**: _From a data transformation perspective, is there a capability gap between Data Flow and pure Spark in Databricks(for example)?_

**A**: 

---

### **Q**: _Since Excel files are always complicated in terms of structure, will this support come with the Wrangling Data Flows (similar to the Dataflows or Power Query capability in Power BI) to deal with real-world Excel files?_

**A**: 

---

### **Q**: _Is Azure Synapse Apache Spark leveraging vanilla Spark or Databricks Spark or our variation of Spark?_

**A**: 

---

### **Q**: _Very interested to see clear guidance when we suggest ASA Spark ML and when to look into AML service integration._

**A**: 

---

### **Q**: _Will auto scale be supported like ADB?_

**A**: 

---

### **Q**: _Can Synapse share a common Metastore over several Synapse Workspaces within one Azure Region? This is possible with HDInsight and Azure Databricks. Some customers rely on that support._

**A**: 

---

### **Q**: _Is it possible to encrypt Notebooks with customer-managed keys?_

**A**: 

---

### **Q**: _Will there be connectors available for 3rd party services like Qlik? Maybe SnowFlake? I know we want to use Synapse, but sometimes customers have chosen their platforms._

**A**: 

---

### **Q**: _Is it possible to handle and manage multiple python environments in a Synapse notebook ? or User has to create a new spark cluster?_

**A**: 

---

### **Q**: _?_

**A**: 

---